import argparse
from utils.generate_prompts import inference_prompts, generate_prompts_all_pairs_repeated,generate_simple_prompts
from utils.generate_images import generate_images, generate_images_accelerate
import random

def parse_args(parser):
    parser = add_train_args(parser)
    args = parser.parse_args()
    return post_parse(args)

def add_train_args(parser):
# args are not fully cleaned (yet)
# Parameters for synthetic image generation
    parser.add_argument(
        "--dataset",
        type=str,
        default="imagenet",
        help="Select dataset from: imagenet, pets, cars, food, flowers, aircraft, texture",
    )
    parser.add_argument(
        "--logdir",
        type=str,
        help="The directory the logs will be saved to.",
        required=True,
    )
    parser.add_argument(
        "--synthetic_data",#default=True,
        type=str,
        help="Set to true if distilling with synthetic data.",
        required=True,
    )
    parser.add_argument(
        "--train",
        type=str,
        help="The directory where the training data set is stored",
        action="append",
    )
    parser.add_argument(
        "--CLIP_filter",
        default="False",
        help="Set to true in order to filter images by CLIP teacher model",
    )
    parser.add_argument(
        "--teacher",
        type=str,
        default="ViT-B-32",
        help="Architecture of the teacher model, select from open_clip (used for optional CLIP filtering).",
    )
    parser.add_argument(
        "--teacher_pretrained",
        type=str,
        default="openai",
        help="Pretraining dataset of teacher (used for optional CLIP filtering).",
    )
    parser.add_argument(
        "--Text_to_Image_model",
        type=str,
        help="Path to the model to be used",
        default="SimianLuo/LCM_Dreamshaper_v7",
    )
    parser.add_argument(
        "--savedir",
        type=str,
        help="Path to the directory to save dataset to",
        #required=True,
    )
    parser.add_argument(
        "--guidance_scale",
        type=float,
        default=0.5,
        help="Guidance scale parameter used by Stable Diffusion.",
    )
    parser.add_argument(
        "--num_inference_steps",
        type=int,
        default=4,
        help="Number of inference steps per image used by Stable Diffusion.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=random.randint(1,9999999999),
        help="Random seed used by Stable Diffusion and for sampling batches. Set to the same seed for all partial jobs for replicable results.",
    )
    parser.add_argument(
        "--simple_prompts",
        default=False,
        help="Set this flag to use synset names instead of definition prompts",
    )
    parser.add_argument(
        "--normalize_channels",
        action="store_true",
        default=True,
        help="Set this parameter to true to normalize the image channels",
    )
# Parameters for the prompt generation
    parser.add_argument(
        "--diverse_prompts",#default=False,
        type=str,
        help="Set this flag to use diverse prompts generated by Zephyr-7B based on the class names.",
        required=True,
    )
    parser.add_argument(
        "--generate_prompts",#default=True,
        type=str,
        help="Set this flag to generate new prompts.",
        required=True,
    )
    parser.add_argument(
        "--generate_images",#default=True,
        type=str,
        help="Set this flag to generate new images.",
        required=True,
    )
    parser.add_argument(
        "--all_pairs_prompts",#default=True,
        type=str,
        help="Set this flag to generate new prompts.",
        required=True,
    )
    parser.add_argument(
        "--LLM_model",
        type=str,
        default="HuggingFaceH4/zephyr-7b-alpha",
        help="Path to the model to be used",
    )
    parser.add_argument(
        "--options_per_attribute",
        type=int,
        default=2,
        help="Number of options for diverse prompts w.r.t. location, daytime, position, camera angle",
    )
    parser.add_argument(
        "--LLM_max_tokens",
        type=int,
        default=32,
        help="Maximum number of new tokens to generate from the LLM.",
    )
    parser.add_argument(
        "--LLM_temperature",
        type=float,
        default=0.9,
        help="Temperature parameter used by LLM.",
    )
    parser.add_argument(
        "--LLM_top_k",
        type=int,
        default=25,
        help="Top-k parameter used by LLM.",
    )
    parser.add_argument(
        "--LLM_top_p",
        type=float,
        default=0.95,
        help="Top-p parameter used by LLM.",
    )
    parser.add_argument(
        "--logname",
        type=str,
        default="",
        help="Name of the experiment, will be used as name of the resulting tensorboard.",
        required=True,
    )
# hardware
    parser.add_argument(
        "--devices",
        type=int,
        default=1,
        help="Number of gpus per node.",
    )
    parser.add_argument(
        "--nodes",
        type=int,
        default=1,
        help="Number of nodes.",
    )
    return parser

def parse_args(parser):
    parser = add_train_args(parser)
    args = parser.parse_args()
    return post_parse(args)

def post_parse(args):
    if args.dataset=="imagenet":
        if args.train_class_ids[0][0]==1000:
            args.train_class_ids=[[i for i in range(1000)]]
        if args.val_class_ids!=None:
            if args.val_class_ids[0][0]==1000:
                args.val_class_ids=[[i for i in range(1000)]]
        train_class_ids = [id for sublist in args.train_class_ids for id in sublist]
        args.distil_prompts = [inference_prompts(args.dataset,id) for id in train_class_ids]
    elif args.dataset=="pets":
        train_class_ids = [id for id in range(37)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    elif args.dataset=="food":
        train_class_ids = [id for id in range(101)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    elif args.dataset=="cars":
        train_class_ids = [id for id in range(196)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    elif args.dataset=="flowers":
        train_class_ids = [id for id in range(102)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    elif args.dataset=="texture":
        train_class_ids = [id for id in range(47)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    elif args.dataset=="aircraft":
        train_class_ids = [id for id in range(100)]
        args.train_class_ids = [train_class_ids]
        args.val_class_ids = [train_class_ids]
    if args.dataset!="datacomp":
        args.num_train_classes = len([id for sublist in args.train_class_ids for id in sublist])
    return args
        
if __name__ == "__main__":
    parser = argparse.ArgumentParser("Configuration")
    args = parse_args(parser)
    # Check if generate_prompts flag is set to True
    if eval(args.generate_prompts)==True:
        # Check if diverse_prompts flag is set to True
        if args.diverse_prompts=="True":
            # Generate prompts using generate_prompts_all_pairs_repeated function, TO DO: LLM args are not used in the current version but set to default
            args.captions, args.n_train_images_per_class = generate_prompts_all_pairs_repeated(args.dataset,args.train_class_ids[0],args.LLM_model,args.LLM_max_tokens,args.LLM_temperature,args.LLM_top_k,args.LLM_top_p,args.train,args.options_per_attribute)
        else:
            # Generate prompts using generate_simple_prompts function
            args.captions = generate_simple_prompts(args.dataset,args.train_class_ids[0],args.options_per_attribute,args.train)
            args.n_train_images_per_class=args.options_per_attribute
    # Check if generate_images flag is set to True
    if eval(args.generate_images)==True:
        # Check if devices is set to 1
        if args.devices==1:
            # Generate images using generate_images function
            generate_images(args)
        else:
            # Generate images in distributed fashion
            print("Generate images in distributed fashion")
            generate_images_accelerate(args)
